{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML7 Практика\n",
    "\n",
    "Наша практика будет основана на соревновании Kaggle: Predicting a Biological Response (Прогнозирование биологического ответа).\n",
    "\n",
    "Необходимо предсказать биологический ответ молекул (столбец '`Activity`') по их химическому составу (столбцы `D1-D1776`).\n",
    "\n",
    "Данные представлены в формате CSV.  Каждая строка представляет молекулу. \n",
    "\n",
    "Первый столбец `Activity` содержит экспериментальные данные, описывающие фактический биологический ответ `[0, 1]`; \n",
    "Остальные столбцы `D1-D1776` представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n",
    "\n",
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать `F1-score`.\n",
    "\n",
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (`GridSeachCV`, `RandomizedSearchCV`, `Hyperopt`, `Optuna`) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, space_eval, fmin\n",
    "import optuna\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выносим глобальные переменные\n",
    "random_state = 42\n",
    "iter_number = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/_train_sem09__1_.zip')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на сбалансированность классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Activity', ylabel='count'>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtC0lEQVR4nO3dfVRVdaL/8c8BPQctwBDhwJXQrHxKscyIZnJ8uiAyzjRZN3xIJknLQVtJY1zuMkOaiUYnswdvXef6MK0Lad1bVtp1REroGmZRhFpROhbOkoNOCSdo5Mnz+2OG/euEjwieQ9/3a629Fnvv79n7u1nLeq999jnYPB6PRwAAAAYL8PUEAAAAfI0gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxevh6At3ByZMndeTIEQUHB8tms/l6OgAA4Bx4PB598803io6OVkDAme8BEUTn4MiRI4qJifH1NAAAQAccPnxY/fv3P+MYgugcBAcHS/r7LzQkJMTHswEAAOfC7XYrJibG+v/4mRBE56DtbbKQkBCCCACAbuZcHnfhoWoAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMbr4esJAIAJqnJH+HoKgF+6fOleX09BEneIAAAAfBtEeXl5GjNmjIKDgxUREaFbbrlFlZWVXmNOnDihjIwM9e3bV5deeqmmTZummpoarzFVVVVKSUlR7969FRERocWLF6ulpcVrzM6dO3XdddfJ4XDoyiuv1IYNG7r68gAAQDfh0yAqLi5WRkaGdu/ercLCQjU3NysxMVENDQ3WmEWLFun111/XSy+9pOLiYh05ckS33nqrtb+1tVUpKSlqamrSO++8oz/+8Y/asGGDli5dao05dOiQUlJSNH78eJWXl+v+++/X3XffrT/96U8X9XoBAIB/snk8Ho+vJ9Hm2LFjioiIUHFxscaOHau6ujr169dPBQUFuu222yRJn376qYYOHarS0lLdeOON+t///V/99Kc/1ZEjRxQZGSlJeu6555SVlaVjx47JbrcrKytLW7du1b59+6xzpaamqra2Vtu2bTvrvNxut0JDQ1VXV6eQkJCuuXgAP2g8QwScWlc+Q3Q+///2q2eI6urqJElhYWGSpLKyMjU3N2vSpEnWmCFDhujyyy9XaWmpJKm0tFQjRoywYkiSkpKS5Ha7tX//fmvMd4/RNqbtGN/X2Ngot9vttQAAgB8uvwmikydP6v7779ePfvQjXXPNNZIkl8slu92uPn36eI2NjIyUy+Wyxnw3htr2t+070xi3262//e1v7eaSl5en0NBQa4mJiemUawQAAP7Jb4IoIyND+/bt08aNG309FWVnZ6uurs5aDh8+7OspAQCALuQX30O0YMECbdmyRSUlJerfv7+13el0qqmpSbW1tV53iWpqauR0Oq0xe/bs8Tpe26fQvjvm+59Mq6mpUUhIiHr16tVuPg6HQw6Ho1OuDQAA+D+f3iHyeDxasGCBXnnlFb355psaOHCg1/7Ro0erZ8+eKioqsrZVVlaqqqpKCQkJkqSEhATt3btXR48etcYUFhYqJCREw4YNs8Z89xhtY9qOAQAAzObTO0QZGRkqKCjQq6++quDgYOuZn9DQUPXq1UuhoaFKT09XZmamwsLCFBISooULFyohIUE33nijJCkxMVHDhg3TnXfeqeXLl8vlcmnJkiXKyMiw7vLce++9euaZZ/Tggw9qzpw5evPNN/Xiiy9q69atPrt2AADgP3x6h+jZZ59VXV2dxo0bp6ioKGvZtGmTNeaJJ57QT3/6U02bNk1jx46V0+nUyy+/bO0PDAzUli1bFBgYqISEBM2aNUuzZ89Wbm6uNWbgwIHaunWrCgsLFRcXp8cff1z/+Z//qaSkpIt6vQAAwD/51fcQ+Su+hwjAheJ7iIBT43uIAAAA/ARBBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4Pg2ikpISTZ06VdHR0bLZbNq8ebPXfpvNdsplxYoV1pgBAwa02//YY495HaeiokI333yzgoKCFBMTo+XLl1+MywMAAN2ET4OooaFBcXFxWr169Sn3V1dXey3r1q2TzWbTtGnTvMbl5uZ6jVu4cKG1z+12KzExUbGxsSorK9OKFSuUk5OjNWvWdOm1AQCA7qOHL0+enJys5OTk0+53Op1e66+++qrGjx+vK664wmt7cHBwu7Ft8vPz1dTUpHXr1slut2v48OEqLy/XypUrNW/evAu/CAAA0O11m2eIampqtHXrVqWnp7fb99hjj6lv37669tprtWLFCrW0tFj7SktLNXbsWNntdmtbUlKSKisrdfz48VOeq7GxUW6322sBAAA/XD69Q3Q+/vjHPyo4OFi33nqr1/b77rtP1113ncLCwvTOO+8oOztb1dXVWrlypSTJ5XJp4MCBXq+JjIy09l122WXtzpWXl6dly5Z10ZUAAAB/022CaN26dZo5c6aCgoK8tmdmZlo/jxw5Una7Xffcc4/y8vLkcDg6dK7s7Gyv47rdbsXExHRs4gAAwO91iyB6++23VVlZqU2bNp11bHx8vFpaWvTFF19o8ODBcjqdqqmp8RrTtn66544cDkeHYwoAAHQ/3eIZorVr12r06NGKi4s769jy8nIFBAQoIiJCkpSQkKCSkhI1NzdbYwoLCzV48OBTvl0GAADM49Mgqq+vV3l5ucrLyyVJhw4dUnl5uaqqqqwxbrdbL730ku6+++52ry8tLdWqVav00Ucf6c9//rPy8/O1aNEizZo1y4qdGTNmyG63Kz09Xfv379emTZv05JNPer0lBgAAzObTt8zef/99jR8/3lpvi5S0tDRt2LBBkrRx40Z5PB5Nnz693esdDoc2btyonJwcNTY2auDAgVq0aJFX7ISGhmr79u3KyMjQ6NGjFR4erqVLl/KRewAAYLF5PB6Pryfh79xut0JDQ1VXV6eQkJAuO8/oxc932bGB7qxsxWxfT+GCVeWO8PUUAL90+dK9XXbs8/n/d7d4hggAAKArEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4/k0iEpKSjR16lRFR0fLZrNp8+bNXvt/+ctfymazeS2TJ0/2GvP1119r5syZCgkJUZ8+fZSenq76+nqvMRUVFbr55psVFBSkmJgYLV++vKsvDQAAdCM+DaKGhgbFxcVp9erVpx0zefJkVVdXW8sLL7zgtX/mzJnav3+/CgsLtWXLFpWUlGjevHnWfrfbrcTERMXGxqqsrEwrVqxQTk6O1qxZ02XXBQAAupcevjx5cnKykpOTzzjG4XDI6XSect8nn3yibdu26b333tP1118vSXr66ac1ZcoU/f73v1d0dLTy8/PV1NSkdevWyW63a/jw4SovL9fKlSu9wum7Ghsb1djYaK273e4OXiEAAOgO/P4Zop07dyoiIkKDBw/W/Pnz9dVXX1n7SktL1adPHyuGJGnSpEkKCAjQu+++a40ZO3as7Ha7NSYpKUmVlZU6fvz4Kc+Zl5en0NBQa4mJiemiqwMAAP7Ar4No8uTJev7551VUVKTf/e53Ki4uVnJyslpbWyVJLpdLERERXq/p0aOHwsLC5HK5rDGRkZFeY9rW28Z8X3Z2turq6qzl8OHDnX1pAADAj/j0LbOzSU1NtX4eMWKERo4cqUGDBmnnzp2aOHFil53X4XDI4XB02fEBAIB/8es7RN93xRVXKDw8XAcOHJAkOZ1OHT161GtMS0uLvv76a+u5I6fTqZqaGq8xbeunezYJAACYpVsF0V/+8hd99dVXioqKkiQlJCSotrZWZWVl1pg333xTJ0+eVHx8vDWmpKREzc3N1pjCwkINHjxYl1122cW9AAAA4Jd8GkT19fUqLy9XeXm5JOnQoUMqLy9XVVWV6uvrtXjxYu3evVtffPGFioqK9POf/1xXXnmlkpKSJElDhw7V5MmTNXfuXO3Zs0e7du3SggULlJqaqujoaEnSjBkzZLfblZ6erv3792vTpk168sknlZmZ6avLBgAAfsanQfT+++/r2muv1bXXXitJyszM1LXXXqulS5cqMDBQFRUV+tnPfqarr75a6enpGj16tN5++22v53vy8/M1ZMgQTZw4UVOmTNGPf/xjr+8YCg0N1fbt23Xo0CGNHj1aDzzwgJYuXXraj9wDAADz+PSh6nHjxsnj8Zx2/5/+9KezHiMsLEwFBQVnHDNy5Ei9/fbb5z0/AABghm71DBEAAEBXIIgAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGM+nQVRSUqKpU6cqOjpaNptNmzdvtvY1NzcrKytLI0aM0CWXXKLo6GjNnj1bR44c8TrGgAEDZLPZvJbHHnvMa0xFRYVuvvlmBQUFKSYmRsuXL78YlwcAALoJnwZRQ0OD4uLitHr16nb7vv32W33wwQd66KGH9MEHH+jll19WZWWlfvazn7Ubm5ubq+rqamtZuHChtc/tdisxMVGxsbEqKyvTihUrlJOTozVr1nTptQEAgO6jhy9PnpycrOTk5FPuCw0NVWFhode2Z555RjfccIOqqqp0+eWXW9uDg4PldDpPeZz8/Hw1NTVp3bp1stvtGj58uMrLy7Vy5UrNmzfvlK9pbGxUY2Ojte52u8/30gAAQDfSrZ4hqqurk81mU58+fby2P/bYY+rbt6+uvfZarVixQi0tLda+0tJSjR07Vna73dqWlJSkyspKHT9+/JTnycvLU2hoqLXExMR0yfUAAAD/0G2C6MSJE8rKytL06dMVEhJibb/vvvu0ceNGvfXWW7rnnnv06KOP6sEHH7T2u1wuRUZGeh2rbd3lcp3yXNnZ2aqrq7OWw4cPd8EVAQAAf+HTt8zOVXNzs/7lX/5FHo9Hzz77rNe+zMxM6+eRI0fKbrfrnnvuUV5enhwOR4fO53A4OvxaAADQ/fj9HaK2GPryyy9VWFjodXfoVOLj49XS0qIvvvhCkuR0OlVTU+M1pm39dM8dAQAAs/h1ELXF0Oeff64dO3aob9++Z31NeXm5AgICFBERIUlKSEhQSUmJmpubrTGFhYUaPHiwLrvssi6bOwAA6D58+pZZfX29Dhw4YK0fOnRI5eXlCgsLU1RUlG677TZ98MEH2rJli1pbW61nfsLCwmS321VaWqp3331X48ePV3BwsEpLS7Vo0SLNmjXLip0ZM2Zo2bJlSk9PV1ZWlvbt26cnn3xSTzzxhE+uGQAA+B+fBtH777+v8ePHW+ttzwOlpaUpJydHr732miRp1KhRXq976623NG7cODkcDm3cuFE5OTlqbGzUwIEDtWjRIq/nikJDQ7V9+3ZlZGRo9OjRCg8P19KlS0/7kXsAAGAenwbRuHHj5PF4Trv/TPsk6brrrtPu3bvPep6RI0fq7bffPu/5AQAAM/j1M0QAAAAXA0EEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAON1KIgmTJig2tradtvdbrcmTJhwoXMCAAC4qDoURDt37lRTU1O77SdOnOALEAEAQLdzXt9UXVFRYf388ccfW39bTJJaW1u1bds2/dM//VPnzQ4AAOAiOK8gGjVqlGw2m2w22ynfGuvVq5eefvrpTpscAADAxXBeQXTo0CF5PB5dccUV2rNnj/r162fts9vtioiIUGBgYKdPEgAAoCudVxDFxsZKkk6ePNklkwEAAPCFDv+1+88//1xvvfWWjh492i6Qli5desETAwAAuFg6FER/+MMfNH/+fIWHh8vpdMpms1n7bDYbQQQAALqVDgXRb37zG/32t79VVlZWZ88HAADgouvQ9xAdP35ct99+e2fPBQAAwCc6FES33367tm/f3tlzAQAA8IkOvWV25ZVX6qGHHtLu3bs1YsQI9ezZ02v/fffd1ymTAwAAuBg6FERr1qzRpZdequLiYhUXF3vts9lsBBEAAOhWOhREhw4d6ux5AAAA+EyHniECAAD4IenQHaI5c+accf+6des6NBkAAABf6FAQHT9+3Gu9ublZ+/btU21t7Sn/6CsAAIA/61AQvfLKK+22nTx5UvPnz9egQYMueFIAAAAXU6c9QxQQEKDMzEw98cQTnXVIAACAi6JTH6o+ePCgWlpaOvOQAAAAXa5Db5llZmZ6rXs8HlVXV2vr1q1KS0vrlIkBAABcLB0Kog8//NBrPSAgQP369dPjjz9+1k+gAQAA+JsOBdFbb73V2fMAAADwmQ4FUZtjx46psrJSkjR48GD169evUyYFAABwMXXooeqGhgbNmTNHUVFRGjt2rMaOHavo6Gilp6fr22+/7ew5AgAAdKkOBVFmZqaKi4v1+uuvq7a2VrW1tXr11VdVXFysBx544JyPU1JSoqlTpyo6Olo2m02bN2/22u/xeLR06VJFRUWpV69emjRpkj7//HOvMV9//bVmzpypkJAQ9enTR+np6aqvr/caU1FRoZtvvllBQUGKiYnR8uXLO3LZAADgB6pDQfQ///M/Wrt2rZKTkxUSEqKQkBBNmTJFf/jDH/Tf//3f53ychoYGxcXFafXq1afcv3z5cj311FN67rnn9O677+qSSy5RUlKSTpw4YY2ZOXOm9u/fr8LCQm3ZskUlJSWaN2+etd/tdisxMVGxsbEqKyvTihUrlJOTozVr1nTk0gEAwA9Qh54h+vbbbxUZGdlue0RExHm9ZZacnKzk5ORT7vN4PFq1apWWLFmin//855Kk559/XpGRkdq8ebNSU1P1ySefaNu2bXrvvfd0/fXXS5KefvppTZkyRb///e8VHR2t/Px8NTU1ad26dbLb7Ro+fLjKy8u1cuVKr3ACAADm6tAdooSEBD388MNed2r+9re/admyZUpISOiUiR06dEgul0uTJk2ytoWGhio+Pl6lpaWSpNLSUvXp08eKIUmaNGmSAgIC9O6771pjxo4dK7vdbo1JSkpSZWVlu7/J1qaxsVFut9trAQAAP1wdukO0atUqTZ48Wf3791dcXJwk6aOPPpLD4dD27ds7ZWIul0uS2t2JioyMtPa5XC5FRER47e/Ro4fCwsK8xgwcOLDdMdr2XXbZZe3OnZeXp2XLlnXKdQAAAP/XoSAaMWKEPv/8c+Xn5+vTTz+VJE2fPl0zZ85Ur169OnWCvpCdne31bdxut1sxMTE+nBEAAOhKHQqivLw8RUZGau7cuV7b161bp2PHjikrK+uCJ+Z0OiVJNTU1ioqKsrbX1NRo1KhR1pijR496va6lpUVff/219Xqn06mamhqvMW3rbWO+z+FwyOFwXPA1AACA7qFDzxD9x3/8h4YMGdJu+/Dhw/Xcc89d8KQkaeDAgXI6nSoqKrK2ud1uvfvuu9ZzSgkJCaqtrVVZWZk15s0339TJkycVHx9vjSkpKVFzc7M1prCwUIMHDz7l22UAAMA8HQoil8vlddemTb9+/VRdXX3Ox6mvr1d5ebnKy8sl/f1B6vLyclVVVclms+n+++/Xb37zG7322mvau3evZs+erejoaN1yyy2SpKFDh2ry5MmaO3eu9uzZo127dmnBggVKTU1VdHS0JGnGjBmy2+1KT0/X/v37tWnTJj355JPt/kAtAAAwV4feMouJidGuXbvaPay8a9cuK0TOxfvvv6/x48db622RkpaWpg0bNujBBx9UQ0OD5s2bp9raWv34xz/Wtm3bFBQUZL0mPz9fCxYs0MSJExUQEKBp06bpqaeesvaHhoZq+/btysjI0OjRoxUeHq6lS5fykXsAAGDpUBDNnTtX999/v5qbmzVhwgRJUlFRkR588MHz+qbqcePGyePxnHa/zWZTbm6ucnNzTzsmLCxMBQUFZzzPyJEj9fbbb5/zvAAAgFk6FESLFy/WV199pV/96ldqamqSJAUFBSkrK0vZ2dmdOkEAAICu1qEgstls+t3vfqeHHnpIn3zyiXr16qWrrrqKT2YBAIBuqUNB1ObSSy/VmDFjOmsuAAAAPtGhT5kBAAD8kBBEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADj+X0QDRgwQDabrd2SkZEhSRo3bly7fffee6/XMaqqqpSSkqLevXsrIiJCixcvVktLiy8uBwAA+KEevp7A2bz33ntqbW211vft26d//ud/1u23325tmzt3rnJzc6313r17Wz+3trYqJSVFTqdT77zzjqqrqzV79mz17NlTjz766MW5CAAA4Nf8Poj69evntf7YY49p0KBB+slPfmJt6927t5xO5ylfv337dn388cfasWOHIiMjNWrUKD3yyCPKyspSTk6O7HZ7l84fAAD4P79/y+y7mpqa9F//9V+aM2eObDabtT0/P1/h4eG65pprlJ2drW+//dbaV1paqhEjRigyMtLalpSUJLfbrf3795/yPI2NjXK73V4LAAD44fL7O0TftXnzZtXW1uqXv/yltW3GjBmKjY1VdHS0KioqlJWVpcrKSr388suSJJfL5RVDkqx1l8t1yvPk5eVp2bJlXXMRAADA73SrIFq7dq2Sk5MVHR1tbZs3b57184gRIxQVFaWJEyfq4MGDGjRoUIfOk52drczMTGvd7XYrJiam4xMHAAB+rdsE0ZdffqkdO3ZYd35OJz4+XpJ04MABDRo0SE6nU3v27PEaU1NTI0mnfe7I4XDI4XB0wqwBAEB30G2eIVq/fr0iIiKUkpJyxnHl5eWSpKioKElSQkKC9u7dq6NHj1pjCgsLFRISomHDhnXZfAEAQPfRLe4QnTx5UuvXr1daWpp69Pj/Uz548KAKCgo0ZcoU9e3bVxUVFVq0aJHGjh2rkSNHSpISExM1bNgw3XnnnVq+fLlcLpeWLFmijIwM7gIBAABJ3SSIduzYoaqqKs2ZM8dru91u144dO7Rq1So1NDQoJiZG06ZN05IlS6wxgYGB2rJli+bPn6+EhARdcsklSktL8/reIgAAYLZuEUSJiYnyeDzttsfExKi4uPisr4+NjdUbb7zRFVMDAAA/AN3mGSIAAICuQhABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjEcQAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEAAOMRRAAAwHgEEQAAMB5BBAAAjOfXQZSTkyObzea1DBkyxNp/4sQJZWRkqG/fvrr00ks1bdo01dTUeB2jqqpKKSkp6t27tyIiIrR48WK1tLRc7EsBAAB+rIevJ3A2w4cP144dO6z1Hj3+/5QXLVqkrVu36qWXXlJoaKgWLFigW2+9Vbt27ZIktba2KiUlRU6nU++8846qq6s1e/Zs9ezZU48++uhFvxYAAOCf/D6IevToIafT2W57XV2d1q5dq4KCAk2YMEGStH79eg0dOlS7d+/WjTfeqO3bt+vjjz/Wjh07FBkZqVGjRumRRx5RVlaWcnJyZLfbT3nOxsZGNTY2Wutut7trLg4AAPgFv37LTJI+//xzRUdH64orrtDMmTNVVVUlSSorK1Nzc7MmTZpkjR0yZIguv/xylZaWSpJKS0s1YsQIRUZGWmOSkpLkdru1f//+054zLy9PoaGh1hITE9NFVwcAAPyBXwdRfHy8NmzYoG3btunZZ5/VoUOHdPPNN+ubb76Ry+WS3W5Xnz59vF4TGRkpl8slSXK5XF4x1La/bd/pZGdnq66uzloOHz7cuRcGAAD8il+/ZZacnGz9PHLkSMXHxys2NlYvvviievXq1WXndTgccjgcXXZ8AADgX/z6DtH39enTR1dffbUOHDggp9OppqYm1dbWeo2pqamxnjlyOp3tPnXWtn6q55IAAICZulUQ1dfX6+DBg4qKitLo0aPVs2dPFRUVWfsrKytVVVWlhIQESVJCQoL27t2ro0ePWmMKCwsVEhKiYcOGXfT5AwAA/+TXb5n9+te/1tSpUxUbG6sjR47o4YcfVmBgoKZPn67Q0FClp6crMzNTYWFhCgkJ0cKFC5WQkKAbb7xRkpSYmKhhw4bpzjvv1PLly+VyubRkyRJlZGTwlhgAALD4dRD95S9/0fTp0/XVV1+pX79++vGPf6zdu3erX79+kqQnnnhCAQEBmjZtmhobG5WUlKR///d/t14fGBioLVu2aP78+UpISNAll1yitLQ05ebm+uqSAACAH/LrINq4ceMZ9wcFBWn16tVavXr1acfExsbqjTfe6OypAQCAH5Bu9QwRAABAVyCIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABjPr4MoLy9PY8aMUXBwsCIiInTLLbeosrLSa8y4ceNks9m8lnvvvddrTFVVlVJSUtS7d29FRERo8eLFamlpuZiXAgAA/FgPX0/gTIqLi5WRkaExY8aopaVF//Zv/6bExER9/PHHuuSSS6xxc+fOVW5urrXeu3dv6+fW1lalpKTI6XTqnXfeUXV1tWbPnq2ePXvq0UcfvajXAwAA/JNfB9G2bdu81jds2KCIiAiVlZVp7Nix1vbevXvL6XSe8hjbt2/Xxx9/rB07digyMlKjRo3SI488oqysLOXk5Mhut7d7TWNjoxobG611t9vdSVcEAAD8kV+/ZfZ9dXV1kqSwsDCv7fn5+QoPD9c111yj7Oxsffvtt9a+0tJSjRgxQpGRkda2pKQkud1u7d+//5TnycvLU2hoqLXExMR0wdUAAAB/4dd3iL7r5MmTuv/++/WjH/1I11xzjbV9xowZio2NVXR0tCoqKpSVlaXKykq9/PLLkiSXy+UVQ5KsdZfLdcpzZWdnKzMz01p3u91EEQAAP2DdJogyMjK0b98+/d///Z/X9nnz5lk/jxgxQlFRUZo4caIOHjyoQYMGdehcDodDDofjguYLAAC6j27xltmCBQu0ZcsWvfXWW+rfv/8Zx8bHx0uSDhw4IElyOp2qqanxGtO2frrnjgAAgFn8Oog8Ho8WLFigV155RW+++aYGDhx41teUl5dLkqKioiRJCQkJ2rt3r44ePWqNKSwsVEhIiIYNG9Yl8wYAAN2LX79llpGRoYKCAr366qsKDg62nvkJDQ1Vr169dPDgQRUUFGjKlCnq27evKioqtGjRIo0dO1YjR46UJCUmJmrYsGG68847tXz5crlcLi1ZskQZGRm8LQYAACT5+R2iZ599VnV1dRo3bpyioqKsZdOmTZIku92uHTt2KDExUUOGDNEDDzygadOm6fXXX7eOERgYqC1btigwMFAJCQmaNWuWZs+e7fW9RQAAwGx+fYfI4/GccX9MTIyKi4vPepzY2Fi98cYbnTUtAADwA+PXd4gAAAAuBoIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAYjyACAADGI4gAAIDxCCIAAGA8gggAABiPIAIAAMYjiAAAgPGMCqLVq1drwIABCgoKUnx8vPbs2ePrKQEAAD9gTBBt2rRJmZmZevjhh/XBBx8oLi5OSUlJOnr0qK+nBgAAfMyYIFq5cqXmzp2ru+66S8OGDdNzzz2n3r17a926db6eGgAA8LEevp7AxdDU1KSysjJlZ2db2wICAjRp0iSVlpa2G9/Y2KjGxkZrva6uTpLkdru7dJ6tjX/r0uMD3VVX/9u7GL450errKQB+qSv/fbcd2+PxnHWsEUH017/+Va2trYqMjPTaHhkZqU8//bTd+Ly8PC1btqzd9piYmC6bI4DTC336Xl9PAUBXyQvt8lN88803Cg0983mMCKLzlZ2drczMTGv95MmT+vrrr9W3b1/ZbDYfzgwXg9vtVkxMjA4fPqyQkBBfTwdAJ+Lft1k8Ho+++eYbRUdHn3WsEUEUHh6uwMBA1dTUeG2vqamR0+lsN97hcMjhcHht69OnT1dOEX4oJCSE/2ACP1D8+zbH2e4MtTHioWq73a7Ro0erqKjI2nby5EkVFRUpISHBhzMDAAD+wIg7RJKUmZmptLQ0XX/99brhhhu0atUqNTQ06K677vL11AAAgI8ZE0R33HGHjh07pqVLl8rlcmnUqFHatm1buwetAYfDoYcffrjd26YAuj/+feN0bJ5z+SwaAADAD5gRzxABAACcCUEEAACMRxABAADjEUQAAMB4BBHwPatXr9aAAQMUFBSk+Ph47dmzx9dTAtAJSkpKNHXqVEVHR8tms2nz5s2+nhL8CEEEfMemTZuUmZmphx9+WB988IHi4uKUlJSko0eP+npqAC5QQ0OD4uLitHr1al9PBX6Ij90D3xEfH68xY8bomWeekfT3bzSPiYnRwoUL9a//+q8+nh2AzmKz2fTKK6/olltu8fVU4Ce4QwT8Q1NTk8rKyjRp0iRrW0BAgCZNmqTS0lIfzgwA0NUIIuAf/vrXv6q1tbXdt5dHRkbK5XL5aFYAgIuBIAIAAMYjiIB/CA8PV2BgoGpqary219TUyOl0+mhWAICLgSAC/sFut2v06NEqKiqytp08eVJFRUVKSEjw4cwAAF3NmL92D5yLzMxMpaWl6frrr9cNN9ygVatWqaGhQXfddZevpwbgAtXX1+vAgQPW+qFDh1ReXq6wsDBdfvnlPpwZ/AEfuwe+55lnntGKFSvkcrk0atQoPfXUU4qPj/f1tABcoJ07d2r8+PHttqelpWnDhg0Xf0LwKwQRAAAwHs8QAQAA4xFEAADAeAQRAAAwHkEEAACMRxABAADjEUQAAMB4BBEAADAeQQQAAIxHEAEwzoYNG9SnT59zHr9z507ZbDbV1tZ22ZwA+BZBBKBbKC0tVWBgoFJSUs7rdQMGDNCqVau8tt1xxx367LPPzvkYN910k6qrqxUaGirp/IMKgP8jiAB0C2vXrtXChQtVUlKiI0eOXNCxevXqpYiIiHMeb7fb5XQ6ZbPZLui8APwXQQTA79XX12vTpk2aP3++UlJS2v0hztdff11jxoxRUFCQwsPD9Ytf/EKSNG7cOH355ZdatGiRbDabFTTfvcPz2WefyWaz6dNPP/U65hNPPKFBgwZJ8n7LbOfOnbrrrrtUV1dnHTMnJ0e5ubm65ppr2s191KhReuihhzr5NwKgsxFEAPzeiy++qCFDhmjw4MGaNWuW1q1bp7a/S71161b94he/0JQpU/Thhx+qqKhIN9xwgyTp5ZdfVv/+/ZWbm6vq6mpVV1e3O/bVV1+t66+/Xvn5+V7b8/PzNWPGjHbjb7rpJq1atUohISHWMX/9619rzpw5+uSTT/Tee+9ZYz/88ENVVFTorrvu6sxfB4AuQBAB8Htr167VrFmzJEmTJ09WXV2diouLJUm//e1vlZqaqmXLlmno0KGKi4tTdna2JCksLEyBgYEKDg6W0+mU0+k85fFnzpypF154wVr/7LPPVFZWppkzZ7Yba7fbFRoaKpvNZh3z0ksvVf/+/ZWUlKT169dbY9evX6+f/OQnuuKKKzrtdwGgaxBEAPxaZWWl9uzZo+nTp0uSevTooTvuuENr166VJJWXl2vixIkXdI7U1FR98cUX2r17t6S/3x267rrrNGTIkPM6zty5c/XCCy/oxIkTampqUkFBgebMmXNBcwNwcfTw9QQA4EzWrl2rlpYWRUdHW9s8Ho8cDoeeeeYZ9erV64LP4XQ6NWHCBBUUFOjGG29UQUGB5s+ff97HmTp1qhwOh1555RXZ7XY1Nzfrtttuu+D5Aeh63CEC4LdaWlr0/PPP6/HHH1d5ebm1fPTRR4qOjtYLL7ygkSNHqqio6LTHsNvtam1tPeu5Zs6cqU2bNqm0tFR//vOflZqaet7H7NGjh9LS0rR+/XqtX79eqampnRJsALoed4gA+K0tW7bo+PHjSk9Pt74DqM20adO0du1arVixQhMnTtSgQYOUmpqqlpYWvfHGG8rKypL09+8hKikpUWpqqhwOh8LDw095rltvvVXz58/X/PnzNX78eK87Ut83YMAA1dfXq6ioSHFxcerdu7d69+4tSbr77rs1dOhQSdKuXbs649cA4CLgDhEAv7V27VpNmjSpXQxJfw+i999/X2FhYXrppZf02muvadSoUZowYYL27NljjcvNzdUXX3yhQYMGqV+/fqc9V3BwsKZOnaqPPvrolA9Tf9dNN92ke++9V3fccYf69eun5cuXW/uuuuoq3XTTTRoyZIji4+M7cNUAfMHmafvsKgDggnk8Hl111VX61a9+pczMTF9PB8A54i0zAOgkx44d08aNG+VyufjuIaCbIYgAoJNEREQoPDxca9as0WWXXebr6QA4DwQRAHQSnkAAui8eqgYAAMYjiAAAgPEIIgAAYDyCCAAAGI8gAgAAxiOIAACA8QgiAABgPIIIAAAY7/8B3ulmSkWkdpIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data, x='Activity')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: классы довольно сбалансированны."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём матрицу наблюдений и вектор ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='Activity')\n",
    "y = data['Activity']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на тренировочную и тестовую. Хоть выборка и более менее сбалансирована, всё равно проведём стратифицированное разбиение для чистоты эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN shapes:  (3000, 1776) (3000,)\n",
      "TEST shapes:  (751, 1776) (751,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print('TRAIN shapes: ', X_train.shape, y_train.shape)\n",
    "print('TEST shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём DataFrame для хранения метрик всех методов и моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=['method', 'model', 'F1-train', 'F1-test', 'time', 'params'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **GridSearchCV**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тренировочном наборе: 0.84\n",
      "F1 на тестовом наборе: 0.78\n",
      "лучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "лучшая модель:\n",
      "LogisticRegression(C=0.3, max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = [\n",
    "    {'penalty': ['l2', 'None'],\n",
    "     'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
    "    \n",
    "    {'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
    "    \n",
    "    {'penalty': ['elasticnet', 'l1', 'l2', 'None'],\n",
    "     'solver': ['saga'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "\n",
    "grid_search_lr = model_selection.GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=random_state,\n",
    "        max_iter=1000\n",
    "    ),\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "f1_lr_train = metrics.f1_score(y_train, grid_search_lr.predict(X_train))\n",
    "f1_lr_test = metrics.f1_score(y_test, grid_search_lr.predict(X_test))\n",
    "print(f'F1 на тренировочном наборе: {f1_lr_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_lr_test:.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {grid_search_lr.best_params_}')\n",
    "print(f'лучшая модель:\\n{grid_search_lr.best_estimator_}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'GridSearchCV',\n",
    "    'model': 'LogisticRegression',\n",
    "    'F1-train': round(f1_lr_train,2),\n",
    "    'F1-test': round(f1_lr_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': grid_search_lr.best_params_\n",
    "}, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тренировочном наборе: 0.99\n",
      "F1 на тестовом наборе: 0.80\n",
      "лучшие значения гиперпараметров: {'criterion': 'gini', 'max_depth': 21, 'min_samples_leaf': 2, 'n_estimators': 200}\n",
      "лучшая модель:\n",
      "RandomForestClassifier(max_depth=21, min_samples_leaf=2, n_estimators=200,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [5, 10, 30, 50, 70, 100, 120, 140, 160, 180, 200],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [2, 3, 5, 8, 13, 21],\n",
    "    'min_samples_leaf': [2, 3, 5, 8, 13, 21, 34]\n",
    "}\n",
    "\n",
    "grid_search_rf = model_selection.GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "f1_rf_train = metrics.f1_score(y_train, grid_search_rf.predict(X_train))\n",
    "f1_rf_test = metrics.f1_score(y_test, grid_search_rf.predict(X_test))\n",
    "print(f'F1 на тренировочном наборе: {f1_rf_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_rf_test:.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {grid_search_rf.best_params_}')\n",
    "print(f'лучшая модель:\\n{grid_search_rf.best_estimator_}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'GridSearchCV',\n",
    "    'model': 'RandomForestClassifier',\n",
    "    'F1-train': round(f1_rf_train,2),\n",
    "    'F1-test': round(f1_rf_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': grid_search_rf.best_params_\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **RandomizedSearchCV**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тренировочном наборе: 0.83\n",
      "F1 на тестовом наборе: 0.78\n",
      "лучшие значения гиперпараметров: {'solver': 'saga', 'penalty': 'l1', 'C': 0.23}\n",
      "лучшая модель:\n",
      "LogisticRegression(C=0.23, max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='saga')\n"
     ]
    }
   ],
   "source": [
    "param_distr_lr = [\n",
    "    {'penalty': ['l2', 'None'],\n",
    "     'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
    "    \n",
    "    {'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
    "    \n",
    "    {'penalty': ['elasticnet', 'l1', 'l2', 'None'],\n",
    "     'solver': ['saga'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
    "]\n",
    "\n",
    "random_search_lr = model_selection.RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_distributions=param_distr_lr,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search_lr.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "f1_rs_lr_train = metrics.f1_score(y_train, random_search_lr.predict(X_train))\n",
    "f1_rs_lr_test = metrics.f1_score(y_test, random_search_lr.predict(X_test))\n",
    "print(f'F1 на тренировочном наборе: {f1_rs_lr_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_rs_lr_test:.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {random_search_lr.best_params_}')\n",
    "print(f'лучшая модель:\\n{random_search_lr.best_estimator_}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'RandomizedSearchCV',\n",
    "    'model': 'LogisticRegression',\n",
    "    'F1-train': round(f1_rs_lr_train,2),\n",
    "    'F1-test': round(f1_rs_lr_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': random_search_lr.best_params_\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тренировочном наборе: 0.99\n",
      "F1 на тестовом наборе: 0.81\n",
      "лучшие значения гиперпараметров: {'n_estimators': 237, 'min_samples_leaf': 2, 'max_depth': 18, 'criterion': 'log_loss'}\n",
      "лучшая модель:\n",
      "RandomForestClassifier(criterion='log_loss', max_depth=18, min_samples_leaf=2,\n",
      "                       n_estimators=237, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_distr_rf = {\n",
    "    'n_estimators': list(np.linspace(2, 300, 20, dtype=int)),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': list(np.linspace(2, 40, 10, dtype=int)),\n",
    "    'min_samples_leaf': list(np.linspace(2, 40, 10, dtype=int))\n",
    "}\n",
    "\n",
    "random_search_rf = model_selection.RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_distr_rf,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "f1_rs_rf_train = metrics.f1_score(y_train, random_search_rf.predict(X_train))\n",
    "f1_rs_rf_test = metrics.f1_score(y_test, random_search_rf.predict(X_test))\n",
    "print(f'F1 на тренировочном наборе: {f1_rs_rf_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_rs_rf_test:.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {random_search_rf.best_params_}')\n",
    "print(f'лучшая модель:\\n{random_search_rf.best_estimator_}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'RandomizedSearchCV',\n",
    "    'model': 'RandomForestClassifier',\n",
    "    'F1-train': round(f1_rs_rf_train,2),\n",
    "    'F1-test': round(f1_rs_rf_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': random_search_rf.best_params_\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Hyperopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пространство поиска гиперпараметров\n",
    "# т.к. выбор алгоритма зависит от выбора пенальти, то собираем массив из нескольких пространств\n",
    "space_lr = hp.choice('space', [\n",
    "    {'penalty': hp.choice('penalty1', ['l2', None]),\n",
    "     'solver': hp.choice('solver', ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']),\n",
    "     'C': hp.uniform('C1', 0.01, 1)\n",
    "    },\n",
    "    \n",
    "    {'penalty': hp.choice('penalty2',['l1', 'l2']),\n",
    "     'solver': 'liblinear',\n",
    "     'C': hp.uniform('C2', 0.01, 1)\n",
    "     },\n",
    "    \n",
    "    {'penalty': hp.choice('penalty3',['l1', 'l2', None]), ### 'elasticnet', \n",
    "     'solver': 'saga',\n",
    "     'C': hp.uniform('C3', 0.01, 1)\n",
    "     }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "sace_test = {'penalty': hp.choice('penalty1', ['l2', None]),\n",
    "     'solver': hp.choice('solver', ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']),\n",
    "     'C': hp.uniform('C1', 0.01, 1, 0.1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция минимизации \n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    model_params = {'penalty': params['penalty'],\n",
    "              'solver': params['solver'],\n",
    "              'C': params['C']\n",
    "              }\n",
    "    model = linear_model.LogisticRegression(**model_params, random_state=random_state, max_iter=1000)\n",
    "    score = model_selection.cross_val_score(model, X, y, cv=cv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:22<10:49, 22.39s/trial, best loss: -0.7597800660015992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:56<13:46, 29.54s/trial, best loss: -0.7853881548973571]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [01:00<04:37, 10.67s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.35928e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82489e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [01:06<03:49,  9.18s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [01:31<05:49, 14.58s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [01:58<07:03, 18.40s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [02:01<03:20,  9.57s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [02:32<05:23, 16.20s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [02:38<04:12, 13.27s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [03:01<04:50, 16.16s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [03:02<03:15, 11.48s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [03:32<04:33, 17.08s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [03:42<02:37, 11.26s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [04:05<02:04, 10.37s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [04:37<03:06, 16.95s/trial, best loss: -0.7892107732113662]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [04:47<00:00,  9.59s/trial, best loss: -0.7911749231867716]\n",
      "Наилучшие значения гиперпараметров {'C': 0.020965524378912193, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# подбор гиперпараметров\n",
    "trials_lr = hyperopt.Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_lr = fmin(\n",
    "    hyperopt_lr,\n",
    "    space=space_lr,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=iter_number,\n",
    "    trials=trials_lr,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Наилучшие значения гиперпараметров {space_eval(space_lr, best_lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающем наборе: 0.83\n",
      "F1 на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "# расчитываем метрику F1 на подобранных гиперпараметрах\n",
    "model_lr = linear_model.LogisticRegression(**space_eval(space_lr, best_lr), \n",
    "                                           random_state=random_state,\n",
    "                                           max_iter=1000\n",
    "                                           ).fit(X_train, y_train)\n",
    "\n",
    "f1_ho_lr_train = metrics.f1_score(y_train, model_lr.predict(X_train))\n",
    "f1_ho_lr_test = metrics.f1_score(y_test, model_lr.predict(X_test))\n",
    "\n",
    "print(f'F1 на обучающем наборе: {f1_ho_lr_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_ho_lr_test:.2f}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'Hyperopt',\n",
    "    'model': 'LogisticRegression',\n",
    "    'F1-train': round(f1_ho_lr_train,2),\n",
    "    'F1-test': round(f1_ho_lr_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': space_eval(space_lr, best_lr)\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пространство поиска гиперпараметров\n",
    "space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 2, 300, 5),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 40, 2),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 40, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "# функция минимизации \n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    model_params = {'n_estimators': int(params['n_estimators']),\n",
    "              'criterion': params['criterion'],\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "    model = ensemble.RandomForestClassifier(**model_params, random_state=random_state)\n",
    "    score = model_selection.cross_val_score(model, X, y, cv=cv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:27<00:00,  1.09trial/s, best loss: -0.8167721073950098]\n",
      "Наилучшие значения гиперпараметров {'criterion': 'gini', 'max_depth': 30.0, 'min_samples_leaf': 2.0, 'n_estimators': 60.0}\n"
     ]
    }
   ],
   "source": [
    "# подбор гиперпараметров\n",
    "trials_rf = hyperopt.Trials()\n",
    "\n",
    "start_time = time.time()\n",
    "best_rf = fmin(\n",
    "    hyperopt_rf,\n",
    "    space=space_rf,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=iter_number,\n",
    "    trials=trials_rf,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "end_time = time.time()\n",
    "\n",
    "print(f'Наилучшие значения гиперпараметров {space_eval(space_rf, best_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающем наборе: 0.88\n",
      "F1 на тестовом наборе: 0.69\n"
     ]
    }
   ],
   "source": [
    "# расчитываем метрику F1 на подобранных гиперпараметрах\n",
    "model_rf = ensemble.RandomForestClassifier(criterion=space_eval(space_rf, best_rf)['criterion'],\n",
    "                                           max_depth=int(space_eval(space_rf, best_rf)['max_depth']),\n",
    "                                           min_samples_leaf=int(space_eval(space_rf, best_rf)['min_samples_leaf']),\n",
    "                                           n_estimators=int(space_eval(space_rf, best_rf)['min_samples_leaf']),\n",
    "                                           random_state=random_state\n",
    "                                           ).fit(X_train, y_train)\n",
    "\n",
    "f1_ho_rf_train = metrics.f1_score(y_train, model_rf.predict(X_train))\n",
    "f1_ho_rf_test = metrics.f1_score(y_test, model_rf.predict(X_test))\n",
    "\n",
    "print(f'F1 на обучающем наборе: {f1_ho_rf_train:.2f}')\n",
    "print(f'F1 на тестовом наборе: {f1_ho_rf_test:.2f}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'Hyperopt',\n",
    "    'model': 'RandomForestClassifier',\n",
    "    'F1-train': round(f1_ho_rf_train,2),\n",
    "    'F1-test': round(f1_ho_rf_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': space_eval(space_rf, best_rf)\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# настраиваем оптимизацию гиперпараметров\n",
    "def optuna_lr(trial):\n",
    "    # пространство поиска гиперпараметров\n",
    "\n",
    "    # optuna пока не позволяет задавать несколько suggest_categorical для одного параметра, выдаёт ошибку:\n",
    "    # CategoricalDistribution does not support dynamic value space\n",
    "    # поэтому приходится изощряться с одним выбором.\n",
    "    # иначе код ниже работал бы:\n",
    "    \n",
    "    # solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'])\n",
    "    # penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', None])\n",
    "    # if solver in ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']:\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['l2', None])\n",
    "    # elif solver == 'liblinear':\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    # else:\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['elasticnet', 'l1', 'l2', None])\n",
    "    \n",
    "    solver_and_penalty = trial.suggest_categorical('mark', [\n",
    "        ['lbfgs', 'l2'],\n",
    "        ['lbfgs', None],\n",
    "        ['liblinear', 'l1'],\n",
    "        ['liblinear', 'l2'],\n",
    "        ['newton-cg', 'l2'],\n",
    "        ['newton-cg', None],\n",
    "        ['newton-cholesky', 'l2'],\n",
    "        ['newton-cholesky', None],\n",
    "        ['sag', 'l2'],\n",
    "        ['sag', None],\n",
    "        # ['saga', 'elasticnet'], # по каким-то причинам эта комбинация выдаёт ошибку вызова '-' у int. Разберусь позже.\n",
    "        ['saga', 'l1'],\n",
    "        ['saga', 'l2'],\n",
    "        ['saga', None],\n",
    "    ])\n",
    "    c = trial.suggest_float(\"C\", 0.01, 1.0, step=0.1)\n",
    "    \n",
    "    # создаём и обучаем модель\n",
    "    model_lr = linear_model.LogisticRegression(\n",
    "        solver=solver_and_penalty[0],\n",
    "        penalty=solver_and_penalty[1],\n",
    "        C=c,\n",
    "        random_state=random_state,\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    return metrics.f1_score(y_train, model_lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 23:57:34,540]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:57:38,070]\u001b[0m Trial 0 finished with value: 0.8234239617567971 and parameters: {'mark': ['newton-cholesky', 'l2'], 'C': 0.01}. Best is trial 0 with value: 0.8234239617567971.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:57:44,963]\u001b[0m Trial 1 finished with value: 0.9880478087649402 and parameters: {'mark': ['newton-cholesky', None], 'C': 0.41000000000000003}. Best is trial 1 with value: 0.9880478087649402.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:58:14,616]\u001b[0m Trial 2 finished with value: 0.8275245755138516 and parameters: {'mark': ['saga', 'l1'], 'C': 0.21000000000000002}. Best is trial 1 with value: 0.9880478087649402.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:58:27,407]\u001b[0m Trial 3 finished with value: 0.8871359223300971 and parameters: {'mark': ['saga', 'l2'], 'C': 0.7100000000000001}. Best is trial 1 with value: 0.9880478087649402.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:58:42,715]\u001b[0m Trial 4 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.41000000000000003}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:59:06,168]\u001b[0m Trial 5 finished with value: 0.9212381244253754 and parameters: {'mark': ['saga', None], 'C': 0.41000000000000003}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:59:29,580]\u001b[0m Trial 6 finished with value: 0.9212381244253754 and parameters: {'mark': ['saga', None], 'C': 0.6100000000000001}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:59:53,086]\u001b[0m Trial 7 finished with value: 0.9212381244253754 and parameters: {'mark': ['saga', None], 'C': 0.31000000000000005}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 23:59:53,471]\u001b[0m Trial 8 finished with value: 0.8687235329703569 and parameters: {'mark': ['liblinear', 'l1'], 'C': 0.81}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:00:02,433]\u001b[0m Trial 9 finished with value: 0.878907435508346 and parameters: {'mark': ['saga', 'l2'], 'C': 0.41000000000000003}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:00:20,836]\u001b[0m Trial 10 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:00:38,975]\u001b[0m Trial 11 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:00:56,679]\u001b[0m Trial 12 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.6100000000000001}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:00:59,033]\u001b[0m Trial 13 finished with value: 0.8559448936807429 and parameters: {'mark': ['newton-cg', 'l2'], 'C': 0.11}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:05,799]\u001b[0m Trial 14 finished with value: 0.9895769466584917 and parameters: {'mark': ['lbfgs', None], 'C': 0.6100000000000001}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:14,563]\u001b[0m Trial 15 finished with value: 0.8914493632504549 and parameters: {'mark': ['sag', 'l2'], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:16,608]\u001b[0m Trial 16 finished with value: 0.8831719128329297 and parameters: {'mark': ['lbfgs', 'l2'], 'C': 0.51}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:38,564]\u001b[0m Trial 17 finished with value: 0.9305043050430505 and parameters: {'mark': ['sag', None], 'C': 0.21000000000000002}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:57,924]\u001b[0m Trial 18 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.7100000000000001}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:01:58,297]\u001b[0m Trial 19 finished with value: 0.8839745531657073 and parameters: {'mark': ['liblinear', 'l2'], 'C': 0.51}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:02:17,238]\u001b[0m Trial 20 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.31000000000000005}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:02:36,592]\u001b[0m Trial 21 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:02:54,937]\u001b[0m Trial 22 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.81}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:03:13,918]\u001b[0m Trial 23 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.81}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:03:33,104]\u001b[0m Trial 24 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:04:06,879]\u001b[0m Trial 25 finished with value: 0.86682808716707 and parameters: {'mark': ['saga', 'l1'], 'C': 0.81}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:04:28,898]\u001b[0m Trial 26 finished with value: 0.9305043050430505 and parameters: {'mark': ['sag', None], 'C': 0.7100000000000001}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:04:37,133]\u001b[0m Trial 27 finished with value: 0.9880478087649402 and parameters: {'mark': ['newton-cholesky', None], 'C': 0.91}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:04:44,379]\u001b[0m Trial 28 finished with value: 0.9895769466584917 and parameters: {'mark': ['lbfgs', None], 'C': 0.31000000000000005}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:04:47,303]\u001b[0m Trial 29 finished with value: 0.8234239617567971 and parameters: {'mark': ['newton-cholesky', 'l2'], 'C': 0.01}. Best is trial 4 with value: 0.9972367209088118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 54s, sys: 40 s, total: 28min 34s\n",
      "Wall time: 7min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создаём объект исследования\n",
    "study_lr = optuna.create_study(study_name='LogisticRegression', direction='maximize')\n",
    "start_time = time.time()\n",
    "study_lr.optimize(optuna_lr, n_trials=iter_number)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 1.00\n",
      "f1_score на тестовом наборе: 0.71\n"
     ]
    }
   ],
   "source": [
    "# расчитаем метрики на обучающей и тестовой выборке\n",
    "f1_op_lr_train = study_lr.best_value\n",
    "print(f'f1_score на обучающем наборе: {f1_op_lr_train:.2f}')\n",
    "\n",
    "model_lr_optuna = linear_model.LogisticRegression(\n",
    "        solver=study_lr.best_params['mark'][0],\n",
    "        penalty=study_lr.best_params['mark'][1],\n",
    "        C=study_lr.best_params['C'],\n",
    "        random_state=random_state,\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "f1_op_lr_test = metrics.f1_score(y_test, model_lr_optuna.predict(X_test))\n",
    "print(f'f1_score на тестовом наборе: {f1_op_lr_test:.2f}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'Optuna',\n",
    "    'model': 'LogisticRegression',\n",
    "    'F1-train': round(f1_op_lr_train,2),\n",
    "    'F1-test': round(f1_op_lr_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': study_lr.best_params\n",
    "}, ignore_index=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# настраиваем оптимизацию гиперпараметров\n",
    "def optuna_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 300, step=5)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 40, step=2)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 40, step=2)\n",
    "    \n",
    "    model_rf = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                               criterion=criterion,\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               random_state=random_state\n",
    "                                               ).fit(X_train, y_train)\n",
    "    return metrics.f1_score(y_train, model_rf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-03 00:05:07,160]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:07,987]\u001b[0m Trial 0 finished with value: 0.8823529411764707 and parameters: {'n_estimators': 117, 'criterion': 'gini', 'max_depth': 34, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:09,574]\u001b[0m Trial 1 finished with value: 0.8417569193742478 and parameters: {'n_estimators': 297, 'criterion': 'log_loss', 'max_depth': 24, 'min_samples_leaf': 28}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:10,886]\u001b[0m Trial 2 finished with value: 0.8682779456193355 and parameters: {'n_estimators': 227, 'criterion': 'gini', 'max_depth': 22, 'min_samples_leaf': 16}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:12,309]\u001b[0m Trial 3 finished with value: 0.8420735382760698 and parameters: {'n_estimators': 277, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_leaf': 28}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:13,659]\u001b[0m Trial 4 finished with value: 0.8224242424242424 and parameters: {'n_estimators': 292, 'criterion': 'log_loss', 'max_depth': 30, 'min_samples_leaf': 38}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:14,971]\u001b[0m Trial 5 finished with value: 0.835956416464891 and parameters: {'n_estimators': 277, 'criterion': 'gini', 'max_depth': 18, 'min_samples_leaf': 30}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:15,010]\u001b[0m Trial 6 finished with value: 0.7697468740469655 and parameters: {'n_estimators': 2, 'criterion': 'entropy', 'max_depth': 12, 'min_samples_leaf': 28}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:15,905]\u001b[0m Trial 7 finished with value: 0.8407720144752714 and parameters: {'n_estimators': 172, 'criterion': 'log_loss', 'max_depth': 18, 'min_samples_leaf': 28}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:16,023]\u001b[0m Trial 8 finished with value: 0.8342374924653405 and parameters: {'n_estimators': 17, 'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 24}. Best is trial 0 with value: 0.8823529411764707.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:16,273]\u001b[0m Trial 9 finished with value: 0.8932038834951456 and parameters: {'n_estimators': 32, 'criterion': 'entropy', 'max_depth': 22, 'min_samples_leaf': 10}. Best is trial 9 with value: 0.8932038834951456.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:16,449]\u001b[0m Trial 10 finished with value: 0.7397873531057639 and parameters: {'n_estimators': 77, 'criterion': 'entropy', 'max_depth': 2, 'min_samples_leaf': 8}. Best is trial 9 with value: 0.8932038834951456.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:17,324]\u001b[0m Trial 11 finished with value: 0.9901900674432864 and parameters: {'n_estimators': 97, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9901900674432864.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:17,994]\u001b[0m Trial 12 finished with value: 0.9883649724433557 and parameters: {'n_estimators': 72, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9901900674432864.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:18,870]\u001b[0m Trial 13 finished with value: 0.9889705882352943 and parameters: {'n_estimators': 87, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 11 with value: 0.9901900674432864.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:20,219]\u001b[0m Trial 14 finished with value: 0.9911070223857713 and parameters: {'n_estimators': 147, 'criterion': 'gini', 'max_depth': 38, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:21,484]\u001b[0m Trial 15 finished with value: 0.9289850655288023 and parameters: {'n_estimators': 172, 'criterion': 'gini', 'max_depth': 36, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:22,293]\u001b[0m Trial 16 finished with value: 0.8676737160120847 and parameters: {'n_estimators': 137, 'criterion': 'gini', 'max_depth': 28, 'min_samples_leaf': 16}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:23,519]\u001b[0m Trial 17 finished with value: 0.8689863842662632 and parameters: {'n_estimators': 212, 'criterion': 'gini', 'max_depth': 36, 'min_samples_leaf': 16}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:24,423]\u001b[0m Trial 18 finished with value: 0.9551145038167939 and parameters: {'n_estimators': 112, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:24,710]\u001b[0m Trial 19 finished with value: 0.8849984907938423 and parameters: {'n_estimators': 42, 'criterion': 'gini', 'max_depth': 28, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:25,637]\u001b[0m Trial 20 finished with value: 0.8157337367624811 and parameters: {'n_estimators': 202, 'criterion': 'log_loss', 'max_depth': 36, 'min_samples_leaf': 40}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:26,341]\u001b[0m Trial 21 finished with value: 0.9874425727411946 and parameters: {'n_estimators': 77, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:27,138]\u001b[0m Trial 22 finished with value: 0.9290715372907156 and parameters: {'n_estimators': 107, 'criterion': 'gini', 'max_depth': 40, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:28,473]\u001b[0m Trial 23 finished with value: 0.9911070223857713 and parameters: {'n_estimators': 147, 'criterion': 'gini', 'max_depth': 36, 'min_samples_leaf': 2}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:29,714]\u001b[0m Trial 24 finished with value: 0.9109756097560976 and parameters: {'n_estimators': 157, 'criterion': 'gini', 'max_depth': 32, 'min_samples_leaf': 8}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:30,508]\u001b[0m Trial 25 finished with value: 0.8532608695652174 and parameters: {'n_estimators': 142, 'criterion': 'gini', 'max_depth': 36, 'min_samples_leaf': 20}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:31,939]\u001b[0m Trial 26 finished with value: 0.9299634591961022 and parameters: {'n_estimators': 187, 'criterion': 'gini', 'max_depth': 26, 'min_samples_leaf': 6}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:33,555]\u001b[0m Trial 27 finished with value: 0.8843000303674462 and parameters: {'n_estimators': 242, 'criterion': 'gini', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:34,594]\u001b[0m Trial 28 finished with value: 0.9558330795004569 and parameters: {'n_estimators': 127, 'criterion': 'gini', 'max_depth': 32, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n",
      "\u001b[32m[I 2023-05-03 00:05:35,448]\u001b[0m Trial 29 finished with value: 0.8981818181818183 and parameters: {'n_estimators': 102, 'criterion': 'log_loss', 'max_depth': 34, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.9911070223857713.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 547 ms, total: 28.8 s\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создаём объект исследования\n",
    "study_rf = optuna.create_study(study_name='RandomForestClassifier', direction='maximize')\n",
    "start_time = time.time()\n",
    "study_rf.optimize(optuna_rf, n_trials=iter_number)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.99\n",
      "f1_score на тестовом наборе: 0.80\n"
     ]
    }
   ],
   "source": [
    "# расчитаем метрики на обучающей и тестовой выборке\n",
    "f1_op_rf_train = study_rf.best_value\n",
    "print(f'f1_score на обучающем наборе: {f1_op_rf_train:.2f}')\n",
    "\n",
    "model_rf_optuna = ensemble.RandomForestClassifier(**study_rf.best_params, random_state=random_state).fit(X_train, y_train)\n",
    "\n",
    "f1_op_rf_test = metrics.f1_score(y_test, model_rf_optuna.predict(X_test))\n",
    "print(f'f1_score на тестовом наборе: {f1_op_rf_test:.2f}')\n",
    "\n",
    "result = result.append({\n",
    "    'method':'Optuna',\n",
    "    'model': 'RandomForestClassifier',\n",
    "    'F1-train': round(f1_op_rf_train,2),\n",
    "    'F1-test': round(f1_op_rf_test,2),\n",
    "    'time': end_time - start_time,\n",
    "    'params': study_rf.best_params\n",
    "}, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>F1-train</th>\n",
       "      <th>F1-test</th>\n",
       "      <th>time</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>280.027377</td>\n",
       "      <td>{'C': 0.3, 'penalty': 'l1', 'solver': 'libline...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>621.703355</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 21, 'min_sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>233.610708</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l1', 'C': 0.23}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomizedSearchCV</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.81</td>\n",
       "      <td>38.272711</td>\n",
       "      <td>{'n_estimators': 237, 'min_samples_leaf': 2, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hyperopt</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>287.629344</td>\n",
       "      <td>{'C': 0.020965524378912193, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hyperopt</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.69</td>\n",
       "      <td>27.602776</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 30.0, 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>432.764639</td>\n",
       "      <td>{'mark': ['newton-cg', None], 'C': 0.410000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optuna</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.80</td>\n",
       "      <td>28.285386</td>\n",
       "      <td>{'n_estimators': 147, 'criterion': 'gini', 'ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               method                   model  F1-train  F1-test        time  \\\n",
       "0        GridSearchCV      LogisticRegression      0.84     0.78  280.027377   \n",
       "1        GridSearchCV  RandomForestClassifier      0.99     0.80  621.703355   \n",
       "2  RandomizedSearchCV      LogisticRegression      0.83     0.78  233.610708   \n",
       "3  RandomizedSearchCV  RandomForestClassifier      0.99     0.81   38.272711   \n",
       "4            Hyperopt      LogisticRegression      0.83     0.78  287.629344   \n",
       "5            Hyperopt  RandomForestClassifier      0.88     0.69   27.602776   \n",
       "6              Optuna      LogisticRegression      1.00     0.71  432.764639   \n",
       "7              Optuna  RandomForestClassifier      0.99     0.80   28.285386   \n",
       "\n",
       "                                              params  \n",
       "0  {'C': 0.3, 'penalty': 'l1', 'solver': 'libline...  \n",
       "1  {'criterion': 'gini', 'max_depth': 21, 'min_sa...  \n",
       "2     {'solver': 'saga', 'penalty': 'l1', 'C': 0.23}  \n",
       "3  {'n_estimators': 237, 'min_samples_leaf': 2, '...  \n",
       "4  {'C': 0.020965524378912193, 'penalty': 'l2', '...  \n",
       "5  {'criterion': 'gini', 'max_depth': 30.0, 'min_...  \n",
       "6  {'mark': ['newton-cg', None], 'C': 0.410000000...  \n",
       "7  {'n_estimators': 147, 'criterion': 'gini', 'ma...  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили 2 модели и воспользовались четырьмя разными методами по подбору гиперпараметров.\n",
    "На тестовых наборах данных эти методы дали примерно одинаковые результаты, если измерять метрикой `F1`, в районе 0.8. Только 2 показателя оказались существенно меньше:\n",
    "* `Hyperopt\tRandomForestClassifier`\n",
    "* `Optuna\tLogisticRegression`\n",
    "\n",
    "Но при этом важно обратить внимание на разное количество времени, потраченное на обучение моделей и подбор параметров.\n",
    "* Наибольшее количество времени понадобилось методу `GridSearchCV`, т.к. в нём осуществляется полный перебор заданных параметров.\n",
    "* Наименьшее количество времени понадобилось методу `RandomizedSearchCV`, т.к. он выбирает рандомные показатели. При этом метрика схожа с `GridSearchCV`, но времени затрачено на порядок меньше\n",
    "* Методы `Hyperopt` и `Optuna` показали примерно одинаковое количество времени. `Optuna` для `LogisticRegression` показала большое количество времени, но тут надо проверять настройки метода, возможно дело в этом. При этом эти методы должны учитывать предыдущие состояния, что в теории должно привести к лучшим результатам.\n",
    "\n",
    "Основной вывод: нельзя сказать, что какой-то метод однозначно лучше другого. В идеале надо воспользоваться несколькими методами и выбрать лучший результат. Либо опираться на количество входных данных, ожидаемые затраты по времени и доступные мощности."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
