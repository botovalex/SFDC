{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML7 Практика\n",
    "\n",
    "Наша практика будет основана на соревновании Kaggle: Predicting a Biological Response (Прогнозирование биологического ответа).\n",
    "\n",
    "Необходимо предсказать биологический ответ молекул (столбец '`Activity`') по их химическому составу (столбцы `D1-D1776`).\n",
    "\n",
    "Данные представлены в формате CSV.  Каждая строка представляет молекулу. \n",
    "\n",
    "Первый столбец `Activity` содержит экспериментальные данные, описывающие фактический биологический ответ `[0, 1]`; \n",
    "Остальные столбцы `D1-D1776` представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов.\n",
    "\n",
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать `F1-score`.\n",
    "\n",
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (`GridSeachCV`, `RandomizedSearchCV`, `Hyperopt`, `Optuna`) хотя бы по разу, максимальное количество итераций не должно превышать 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, tpe, space_eval, fmin\n",
    "import optuna\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/_train_sem09__1_.zip')\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем наличие пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на сбалансированность классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Activity', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data, x='Activity')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**: классы довольно сбалансированны."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём матрицу наблюдений и вектор ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='Activity')\n",
    "y = data['Activity']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на тренировочную и тестовую. Хоть выборка и более менее сбалансирована, всё равно проведём стратифицированное разбиение для чистоты эксперименты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN shapes:  (3000, 1776) (3000,)\n",
      "TEST shapes:  (751, 1776) (751,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "print('TRAIN shapes: ', X_train.shape, y_train.shape)\n",
    "print('TEST shapes: ', X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **GridSearchCV**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "210 fits failed out of a total of 490.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l1', 'l2', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "37 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'none' (deprecated), 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "57 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'l1', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'none' (deprecated), 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.76266667 0.76233333 0.76233333 0.762             nan        nan\n",
      "        nan        nan 0.762      0.762      0.762      0.76133333\n",
      "        nan        nan        nan        nan 0.75466667 0.75466667\n",
      " 0.75466667 0.75433333        nan        nan        nan        nan\n",
      " 0.75766667 0.757      0.757      0.757             nan        nan\n",
      "        nan        nan 0.75366667 0.75366667 0.75366667 0.75333333\n",
      "        nan        nan        nan        nan 0.75266667 0.75266667\n",
      " 0.75266667 0.75133333        nan        nan        nan        nan\n",
      " 0.75133333 0.75133333 0.75133333 0.75133333        nan        nan\n",
      "        nan        nan 0.743      0.76033333 0.76       0.76066667\n",
      " 0.76466667 0.754      0.764      0.75733333 0.76233333 0.75333333\n",
      " 0.75833333 0.75033333 0.75766667 0.75              nan 0.743\n",
      " 0.76266667        nan        nan 0.75933333 0.76166667        nan\n",
      "        nan 0.76466667 0.75433333        nan        nan 0.76366667\n",
      " 0.75633333        nan        nan 0.76233333 0.753             nan\n",
      "        nan 0.756      0.751             nan        nan 0.75433333\n",
      " 0.751             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 290 ms, total: 1.47 s\n",
      "Wall time: 4min 31s\n",
      "F1 на тестовом наборе: 0.78\n",
      "лучшие значения гиперпараметров: {'C': 0.3, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "лучшая модель:\n",
      "LogisticRegression(C=0.3, max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "param_grid_lr = [\n",
    "    {'penalty': ['l2', 'None'],\n",
    "     'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
    "    \n",
    "    {'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]},\n",
    "    \n",
    "    {'penalty': ['elasticnet', 'l1', 'l2', 'None'],\n",
    "     'solver': ['saga'],\n",
    "     'C': [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "]\n",
    "\n",
    "grid_search_lr = model_selection.GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(\n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    ),\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time grid_search.fit(X_train, y_train)\n",
    "y_test_gs_pred = grid_search_lr.predict(X_test)\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_true=y_test, y_pred=y_test_gs_pred):.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {grid_search_lr.best_params_}')\n",
    "print(f'лучшая модель:\\n{grid_search_lr.best_estimator_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 2.75 s, total: 19 s\n",
      "Wall time: 9min 58s\n",
      "F1 на тестовом наборе: 0.80\n",
      "лучшие значения гиперпараметров: {'criterion': 'gini', 'max_depth': 21, 'min_samples_leaf': 2, 'n_estimators': 200}\n",
      "лучшая модель:\n",
      "RandomForestClassifier(max_depth=21, min_samples_leaf=2, n_estimators=200,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [5, 10, 30, 50, 70, 100, 120, 140, 160, 180, 200],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [2, 3, 5, 8, 13, 21],\n",
    "    'min_samples_leaf': [2, 3, 5, 8, 13, 21, 34]\n",
    "}\n",
    "\n",
    "grid_search_rf = model_selection.GridSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time grid_search_rf.fit(X_train, y_train)\n",
    "y_test_gs_pred = grid_search_rf.predict(X_test)\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_true=y_test, y_pred=y_test_gs_pred):.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {grid_search_rf.best_params_}')\n",
    "print(f'лучшая модель:\\n{grid_search_rf.best_estimator_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> **RandomizedSearchCV**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "95 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'l1', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'elasticnet', 'l2', 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'l1', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'elasticnet', 'none' (deprecated), 'l2'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l1', 'l2', 'none' (deprecated)} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'elasticnet', 'l2', 'none' (deprecated), 'l1'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l2', 'l1', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'none' (deprecated), 'l1', 'l2', 'elasticnet'} or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.76366667        nan 0.75666667        nan 0.75733333\n",
      " 0.75433333        nan        nan        nan 0.76266667        nan\n",
      " 0.758      0.75533333 0.754             nan 0.75133333 0.76233333\n",
      " 0.76233333        nan        nan        nan        nan        nan\n",
      " 0.75266667 0.76133333 0.756      0.766      0.75633333 0.76233333\n",
      " 0.75766667        nan 0.75233333        nan        nan 0.76233333\n",
      "        nan 0.76166667 0.762             nan 0.76166667 0.76166667\n",
      " 0.75666667 0.75766667 0.743      0.753      0.76266667        nan\n",
      " 0.75       0.762     ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.1 s, sys: 261 ms, total: 30.4 s\n",
      "Wall time: 2min 35s\n",
      "F1 на тестовом наборе: 0.78\n",
      "лучшие значения гиперпараметров: {'solver': 'saga', 'penalty': 'l1', 'C': 0.23}\n",
      "лучшая модель:\n",
      "LogisticRegression(C=0.23, max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='saga')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "param_distr_lr = [\n",
    "    {'penalty': ['l2', 'None'],\n",
    "     'solver': ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
    "    \n",
    "    {'penalty': ['l1', 'l2'],\n",
    "     'solver': ['liblinear'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))},\n",
    "    \n",
    "    {'penalty': ['elasticnet', 'l1', 'l2', 'None'],\n",
    "     'solver': ['saga'],\n",
    "     'C': list(np.linspace(0.01, 1, 10, dtype=float))}\n",
    "]\n",
    "\n",
    "random_search_lr = model_selection.RandomizedSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_distributions=param_distr_lr,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time random_search_lr.fit(X_train, y_train)\n",
    "y_test_rs_pred = random_search_lr.predict(X_test)\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_true=y_test, y_pred=y_test_rs_pred):.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {random_search_lr.best_params_}')\n",
    "print(f'лучшая модель:\\n{random_search_lr.best_estimator_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.89 s, sys: 180 ms, total: 2.07 s\n",
      "Wall time: 40.7 s\n",
      "F1 на тестовом наборе: 0.80\n",
      "лучшие значения гиперпараметров: {'n_estimators': 143, 'min_samples_leaf': 2, 'max_depth': 35, 'criterion': 'gini'}\n",
      "лучшая модель:\n",
      "RandomForestClassifier(max_depth=35, min_samples_leaf=2, n_estimators=143,\n",
      "                       random_state=42)\n"
     ]
    }
   ],
   "source": [
    "param_distr_rf = {\n",
    "    'n_estimators': list(np.linspace(2, 300, 20, dtype=int)),\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': list(np.linspace(2, 40, 10, dtype=int)),\n",
    "    'min_samples_leaf': list(np.linspace(2, 40, 10, dtype=int))\n",
    "}\n",
    "\n",
    "random_search_rf = model_selection.RandomizedSearchCV(\n",
    "    estimator=ensemble.RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_distr_rf,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "%time random_search_rf.fit(X_train, y_train)\n",
    "y_test_rs_pred = random_search_rf.predict(X_test)\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_true=y_test, y_pred=y_test_rs_pred):.2f}')\n",
    "print(f'лучшие значения гиперпараметров: {random_search_rf.best_params_}')\n",
    "print(f'лучшая модель:\\n{random_search_rf.best_estimator_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Hyperopt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пространство поиска гиперпараметров\n",
    "# т.к. выбор алгоритма зависит от выбора пенальти, то собираем массив из нескольких пространств\n",
    "space_lr = hp.choice('space', [\n",
    "    {'penalty': hp.choice('penalty1', ['l2', None]),\n",
    "     'solver': hp.choice('solver', ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']),\n",
    "     'C': hp.quniform('C1', 0.01, 1, 0.1)\n",
    "    },\n",
    "    \n",
    "    {'penalty': hp.choice('penalty2',['l1', 'l2']),\n",
    "    #  'solver': hp.choice('solver2',['liblinear']),\n",
    "     'solver': 'liblinear',\n",
    "     'C': hp.quniform('C2', 0.01, 1, 0.1)\n",
    "     },\n",
    "    \n",
    "    {'penalty': hp.choice('penalty3',['l1', 'l2', None]),\n",
    "    #  'solver': hp.choice('solver3',['saga']), ### 'elasticnet', \n",
    "     'solver': 'saga',\n",
    "     'C': hp.quniform('C3', 0.01, 1, 0.1)\n",
    "     }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "# функция минимизации \n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    model_params = {'penalty': params['penalty'],\n",
    "              'solver': params['solver'],\n",
    "              'C': params['C']\n",
    "              }\n",
    "    model = linear_model.LogisticRegression(**model_params, random_state=random_state, max_iter=1000)\n",
    "    score = model_selection.cross_val_score(model, X, y, cv=cv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                      \n",
      "0.7597800660015992                                    \n",
      "  5%|▌         | 1/20 [00:23<07:26, 23.50s/trial, best loss: -0.7597800660015992]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7852748020277636                                                               \n",
      " 10%|█         | 2/20 [00:56<08:48, 29.35s/trial, best loss: -0.7852748020277636]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.780287361102337                                                                \n",
      "SCORE ==========                                                                 \n",
      "0.7904805344739956                                                               \n",
      " 20%|██        | 4/20 [01:00<02:48, 10.56s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=3.82489e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Ill-conditioned matrix (rcond=1.35928e-23): result may not be accurate.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
      "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
      "The original Linear Algebra message was:\n",
      "Matrix is singular.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7181975947130854                                                               \n",
      " 25%|██▌       | 5/20 [01:06<02:14,  8.99s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7626510635585347                                                               \n",
      " 30%|███       | 6/20 [01:31<03:21, 14.39s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7626510635585347                                                               \n",
      " 35%|███▌      | 7/20 [01:55<03:49, 17.68s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7824159224810836                                                               \n",
      "SCORE ==========                                                                 \n",
      "0.7859587576528776                                                               \n",
      " 45%|████▌     | 9/20 [01:59<01:43,  9.39s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                 \n",
      "0.7871320821532662                                                               \n",
      " 50%|█████     | 10/20 [02:31<02:43, 16.31s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7247201518192498                                                                \n",
      " 55%|█████▌    | 11/20 [02:37<02:00, 13.40s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7626510635585347                                                                \n",
      " 60%|██████    | 12/20 [03:02<02:13, 16.66s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7853471682195051                                                                \n",
      " 65%|██████▌   | 13/20 [03:02<01:22, 11.76s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7871320821532662                                                                \n",
      " 70%|███████   | 14/20 [03:34<01:46, 17.76s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7817081325696608                                                                \n",
      "SCORE ==========                                                                  \n",
      "0.7815833078935646                                                                \n",
      " 80%|████████  | 16/20 [03:44<00:47, 11.79s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7626510635585347                                                                \n",
      " 85%|████████▌ | 17/20 [04:09<00:47, 15.68s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7842972882154436                                                                \n",
      " 90%|█████████ | 18/20 [04:09<00:22, 11.06s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7792172077539339                                                                \n",
      " 95%|█████████▌| 19/20 [04:44<00:18, 18.15s/trial, best loss: -0.7904805344739956]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE ==========                                                                  \n",
      "0.7749609376258741                                                                \n",
      "100%|██████████| 20/20 [04:48<00:00, 14.42s/trial, best loss: -0.7904805344739956]\n",
      "Наилучшие значения гиперпараметров {'C': 0.2, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# подбор гиперпараметров\n",
    "trials_lr = hyperopt.Trials()\n",
    "\n",
    "best_lr = fmin(\n",
    "    hyperopt_lr,\n",
    "    space=space_lr,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials_lr,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "\n",
    "print(f'Наилучшие значения гиперпараметров {space_eval(space_lr, best_lr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающем наборе: 0.86\n",
      "F1 на тестовом наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "# расчитываем метрику F1 на подобранных гиперпараметрах\n",
    "model_lr = linear_model.LogisticRegression(**space_eval(space_lr, best_lr), \n",
    "                                           random_state=random_state,\n",
    "                                           max_iter=1000\n",
    "                                           ).fit(X_train, y_train)\n",
    "\n",
    "y_train_lr_pred = model_lr.predict(X_train)\n",
    "y_test_lr_pred = model_lr.predict(X_test)\n",
    "print(f'F1 на обучающем наборе: {metrics.f1_score(y_train, y_train_lr_pred):.2f}')\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_test, y_test_lr_pred):.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# пространство поиска гиперпараметров\n",
    "space_rf = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 2, 300, 5),\n",
    "    'criterion': hp.choice('criterion', ['gini', 'entropy', 'log_loss']),\n",
    "    'max_depth': hp.quniform('max_depth', 2, 40, 2),\n",
    "    'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 40, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "# функция минимизации \n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    model_params = {'n_estimators': int(params['n_estimators']),\n",
    "              'criterion': params['criterion'],\n",
    "              'max_depth': int(params['max_depth']),\n",
    "              'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "    model = ensemble.RandomForestClassifier(**model_params, random_state=random_state)\n",
    "    score = model_selection.cross_val_score(model, X, y, cv=cv, scoring='f1', n_jobs=-1).mean()\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.76s/trial, best loss: -0.783335935496436]\n",
      "Наилучшие значения гиперпараметров {'criterion': 'entropy', 'max_depth': 36.0, 'min_samples_leaf': 26.0, 'n_estimators': 245.0}\n"
     ]
    }
   ],
   "source": [
    "# подбор гиперпараметров\n",
    "trials_rf = hyperopt.Trials()\n",
    "\n",
    "best_rf = fmin(\n",
    "    hyperopt_rf,\n",
    "    space=space_rf,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials_rf,\n",
    "    rstate=np.random.default_rng(random_state)\n",
    ")\n",
    "\n",
    "print(f'Наилучшие значения гиперпараметров {space_eval(space_rf, best_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на обучающем наборе: 0.84\n",
      "F1 на тестовом наборе: 0.75\n"
     ]
    }
   ],
   "source": [
    "# расчитываем метрику F1 на подобранных гиперпараметрах\n",
    "model_lr = ensemble.RandomForestClassifier(criterion=space_eval(space_rf, best_rf)['criterion'],\n",
    "                                           max_depth=int(space_eval(space_rf, best_rf)['max_depth']),\n",
    "                                           min_samples_leaf=int(space_eval(space_rf, best_rf)['min_samples_leaf']),\n",
    "                                           n_estimators=int(space_eval(space_rf, best_rf)['min_samples_leaf']),\n",
    "                                           random_state=random_state\n",
    "                                           ).fit(X_train, y_train)\n",
    "\n",
    "y_train_rf_pred = model_lr.predict(X_train)\n",
    "y_test_rf_pred = model_lr.predict(X_test)\n",
    "print(f'F1 на обучающем наборе: {metrics.f1_score(y_train, y_train_rf_pred):.2f}')\n",
    "print(f'F1 на тестовом наборе: {metrics.f1_score(y_test, y_test_rf_pred):.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# настраиваем оптимизацию гиперпараметров\n",
    "def optuna_lr(trial):\n",
    "    # пространство поиска гиперпараметров\n",
    "\n",
    "    # optuna пока не позволяет задавать несколько suggest_categorical для одного параметра, выдаёт ошибку:\n",
    "    # CategoricalDistribution does not support dynamic value space\n",
    "    # поэтому приходится изощряться с одним выбором.\n",
    "    # иначе код ниже работал бы:\n",
    "    \n",
    "    # solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'])\n",
    "    # penalty = trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet', None])\n",
    "    # if solver in ['lbfgs', 'newton-cg', 'newton-cholesky', 'sag']:\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['l2', None])\n",
    "    # elif solver == 'liblinear':\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    # else:\n",
    "    #     penalty = trial.suggest_categorical('penalty', ['elasticnet', 'l1', 'l2', None])\n",
    "    \n",
    "    solver_and_penalty = trial.suggest_categorical('mark', [\n",
    "        ['lbfgs', 'l2'],\n",
    "        ['lbfgs', None],\n",
    "        ['liblinear', 'l1'],\n",
    "        ['liblinear', 'l2'],\n",
    "        ['newton-cg', 'l2'],\n",
    "        ['newton-cg', None],\n",
    "        ['newton-cholesky', 'l2'],\n",
    "        ['newton-cholesky', None],\n",
    "        ['sag', 'l2'],\n",
    "        ['sag', None],\n",
    "        # ['saga', 'elasticnet'],\n",
    "        ['saga', 'l1'],\n",
    "        ['saga', 'l2'],\n",
    "        ['saga', None],\n",
    "    ])\n",
    "    c = trial.suggest_float(\"C\", 0.01, 1.0, step=0.1)\n",
    "    \n",
    "    # создаём и обучаем модель\n",
    "    model_lr = linear_model.LogisticRegression(\n",
    "        solver=solver_and_penalty[0],\n",
    "        penalty=solver_and_penalty[1],\n",
    "        C=c,\n",
    "        random_state=random_state,\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    return metrics.f1_score(y_train, model_lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 17:18:19,539]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:18:37,893]\u001b[0m Trial 0 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.51}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:18:49,299]\u001b[0m Trial 1 finished with value: 0.8754922750681612 and parameters: {'mark': ['sag', 'l2'], 'C': 0.31000000000000005}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:19:14,924]\u001b[0m Trial 2 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.21000000000000002}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:19:46,071]\u001b[0m Trial 3 finished with value: 0.838095238095238 and parameters: {'mark': ['saga', 'l1'], 'C': 0.31000000000000005}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:17,559]\u001b[0m Trial 4 finished with value: 0.8558558558558558 and parameters: {'mark': ['saga', 'l1'], 'C': 0.51}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:17,702]\u001b[0m Trial 5 finished with value: 0.757775683317625 and parameters: {'mark': ['liblinear', 'l1'], 'C': 0.01}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:26,389]\u001b[0m Trial 6 finished with value: 0.8902365069739235 and parameters: {'mark': ['sag', 'l2'], 'C': 0.81}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:33,516]\u001b[0m Trial 7 finished with value: 0.9895769466584917 and parameters: {'mark': ['lbfgs', None], 'C': 0.51}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:37,439]\u001b[0m Trial 8 finished with value: 0.8901699029126213 and parameters: {'mark': ['lbfgs', 'l2'], 'C': 0.81}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:37,849]\u001b[0m Trial 9 finished with value: 0.8901699029126213 and parameters: {'mark': ['liblinear', 'l2'], 'C': 0.81}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:20:59,465]\u001b[0m Trial 10 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.6100000000000001}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:21:20,506]\u001b[0m Trial 11 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.11}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:21:26,800]\u001b[0m Trial 12 finished with value: 0.8661037394451147 and parameters: {'mark': ['saga', 'l2'], 'C': 0.21000000000000002}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:21:35,032]\u001b[0m Trial 13 finished with value: 0.9880478087649402 and parameters: {'mark': ['newton-cholesky', None], 'C': 0.31000000000000005}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:21:38,465]\u001b[0m Trial 14 finished with value: 0.8862602365787079 and parameters: {'mark': ['newton-cg', 'l2'], 'C': 0.6100000000000001}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:22:00,679]\u001b[0m Trial 15 finished with value: 0.9305043050430505 and parameters: {'mark': ['sag', None], 'C': 0.41000000000000003}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:22:24,483]\u001b[0m Trial 16 finished with value: 0.9212381244253754 and parameters: {'mark': ['saga', None], 'C': 0.01}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:22:45,428]\u001b[0m Trial 17 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.21000000000000002}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:22:51,604]\u001b[0m Trial 18 finished with value: 0.8862602365787079 and parameters: {'mark': ['newton-cholesky', 'l2'], 'C': 0.6100000000000001}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:23:13,887]\u001b[0m Trial 19 finished with value: 0.9972367209088118 and parameters: {'mark': ['newton-cg', None], 'C': 0.41000000000000003}. Best is trial 0 with value: 0.9972367209088118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 11s, sys: 26.2 s, total: 18min 37s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создаём объект исследования\n",
    "study_lr = optuna.create_study(study_name='LogisticRegression', direction='maximize')\n",
    "study_lr.optimize(optuna_lr, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 1.00\n",
      "f1_score на тестовом наборе: 0.71\n"
     ]
    }
   ],
   "source": [
    "# расчитаем метрики на обучающей и тестовой выборке\n",
    "print(f'f1_score на обучающем наборе: {study_lr.best_value:.2f}')\n",
    "\n",
    "model_lr_optuna = linear_model.LogisticRegression(\n",
    "        solver=study_lr.best_params['mark'][0],\n",
    "        penalty=study_lr.best_params['mark'][1],\n",
    "        C=study_lr.best_params['C'],\n",
    "        random_state=random_state,\n",
    "        max_iter=1000\n",
    "    ).fit(X_train, y_train)\n",
    "\n",
    "y_test_lr_optuna_pred = model_lr_optuna.predict(X_test)\n",
    "print(f'f1_score на тестовом наборе: {metrics.f1_score(y_test, y_test_lr_optuna_pred):.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "\n",
    "# настраиваем оптимизацию гиперпараметров\n",
    "def optuna_rf(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 2, 300, step=5)\n",
    "    criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 40, step=2)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 40, step=2)\n",
    "    \n",
    "    model_rf = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                               criterion=criterion,\n",
    "                                               max_depth=max_depth,\n",
    "                                               min_samples_leaf=min_samples_leaf,\n",
    "                                               random_state=random_state\n",
    "                                               ).fit(X_train, y_train)\n",
    "    return metrics.f1_score(y_train, model_rf.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-02 17:39:28,466]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:39:29,203]\u001b[0m Trial 0 finished with value: 0.8619221411192215 and parameters: {'n_estimators': 107, 'criterion': 'entropy', 'max_depth': 32, 'min_samples_leaf': 18}. Best is trial 0 with value: 0.8619221411192215.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:39:29,966]\u001b[0m Trial 1 finished with value: 0.8314129775621588 and parameters: {'n_estimators': 152, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 32}. Best is trial 0 with value: 0.8619221411192215.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:39:30,212]\u001b[0m Trial 2 finished with value: 0.9299908284928157 and parameters: {'n_estimators': 27, 'criterion': 'entropy', 'max_depth': 30, 'min_samples_leaf': 6}. Best is trial 2 with value: 0.9299908284928157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:39:30,780]\u001b[0m Trial 3 finished with value: 0.8188736681887366 and parameters: {'n_estimators': 112, 'criterion': 'entropy', 'max_depth': 14, 'min_samples_leaf': 36}. Best is trial 2 with value: 0.9299908284928157.\u001b[0m\n",
      "\u001b[32m[I 2023-05-02 17:39:31,665]\u001b[0m Trial 4 finished with value: 0.831965967790945 and parameters: {'n_estimators': 172, 'criterion': 'entropy', 'max_depth': 26, 'min_samples_leaf': 30}. Best is trial 2 with value: 0.9299908284928157.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.09 s, sys: 63.6 ms, total: 3.16 s\n",
      "Wall time: 3.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# создаём объект исследования\n",
    "study_rf = optuna.create_study(study_name='RandomForestClassifier', direction='maximize')\n",
    "study_rf.optimize(optuna_rf, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score на обучающем наборе: 0.93\n",
      "f1_score на тестовом наборе: 0.81\n"
     ]
    }
   ],
   "source": [
    "# расчитаем метрики на обучающей и тестовой выборке\n",
    "print(f'f1_score на обучающем наборе: {study_rf.best_value:.2f}')\n",
    "\n",
    "model_rf_optuna = ensemble.RandomForestClassifier(**study_rf.best_params, random_state=random_state).fit(X_train, y_train)\n",
    "\n",
    "y_test_rf_optuna_pred = model_rf_optuna.predict(X_test)\n",
    "print(f'f1_score на тестовом наборе: {metrics.f1_score(y_test, y_test_rf_optuna_pred):.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
